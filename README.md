# FIAP Tech Challenge 05 - Decision Scoring API

Este projeto cont√©m an√°lises explorat√≥rias de dados para sistema de recrutamento e uma API de scoring para auxiliar na tomada de decis√£o no processo de recrutamento.

## üöÄ Configura√ß√£o do Ambiente

### Pr√©-requisitos
- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Configura√ß√£o Autom√°tica
Execute o script de setup:
```bash
./scripts/setup.sh
```

### Configura√ß√£o Manual
1. Criar ambiente virtual:
```bash
python3 -m venv .venv
```

2. Ativar ambiente virtual:
```bash
source .venv/bin/activate  # macOS/Linux
# ou
.venv\Scripts\activate     # Windows
```

3. Instalar depend√™ncias:
```bash
pip install -r requirements.txt
```

4. Verificar instala√ß√£o:
```bash
python check_env.py
```

## üìä Estrutura do Projeto

```
fiap_tech_challenge_05/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ An√°lise Explorat√≥ria dos Dados.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ analise_exploratoria.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ threshold_adjustment_analysis.ipynb
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ applicants.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prospects.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ jobs.json
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ complete_processed_data.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ splits/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ X_train.csv
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ X_test.csv
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ insights/
‚îÇ   ‚îî‚îÄ‚îÄ visualizations/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_analysis.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ download_data.py
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_validation.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ train_simple.py
‚îÇ       ‚îú‚îÄ‚îÄ train_model.py
‚îÇ       ‚îî‚îÄ‚îÄ mlflow_server.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ scoring_model.pkl
‚îÇ   ‚îî‚îÄ‚îÄ feature_scaler.pkl
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ mlflow_guide.md
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ check_env.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.sh
‚îú‚îÄ‚îÄ check_env.py
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ README.md
```

## üîß Bibliotecas Utilizadas

- **pandas**: Manipula√ß√£o e an√°lise de dados
- **numpy**: Computa√ß√£o cient√≠fica
- **matplotlib**: Visualiza√ß√£o de dados
- **seaborn**: Visualiza√ß√£o estat√≠stica
- **plotly**: Gr√°ficos interativos
- **scikit-learn**: Machine learning
- **fastapi**: Framework para API
- **jupyter**: Ambiente de notebooks
- **mlflow**: Rastreamento e gerenciamento de experimentos de ML
- **textblob**: Processamento de linguagem natural para LLM

## üìà Como Usar

1. Ativar o ambiente virtual:
```bash
source .venv/bin/activate
```

2. Iniciar Jupyter Notebook:
```bash
jupyter notebook
```

3. Abrir o notebook [`notebooks/An√°lise Explorat√≥ria dos Dados.ipynb`](notebooks/An√°lise%20Explorat√≥ria%20dos%20Dados.ipynb)

## üõ†Ô∏è Vari√°veis de Ambiente

Para configurar a API, voc√™ pode usar diversas vari√°veis de ambiente:
- `PORT`: Porta onde a API ser√° executada (padr√£o: 8000)
- `LOG_LEVEL`: N√≠vel de logging (padr√£o: INFO)
- `CLASSIFICATION_THRESHOLD`: Threshold para classifica√ß√£o de candidatos (padr√£o: 0.5)

Veja a lista completa em [docs/env_variables.md](docs/env_variables.md).

## ü§ñ Sistema H√≠brido de Scoring + Clustering

### Pipeline Completo

Execute o pipeline completo com MLflow usando:

```bash
./scripts/run_pipeline.sh
```

Op√ß√µes dispon√≠veis:
- `--compare`: Treina e compara diferentes modelos
- `--port 8080`: Altera a porta do servidor MLflow (padr√£o: 5001)
- `--no-server`: Executa o pipeline sem iniciar o servidor MLflow
- `--no-cv`: Desativa a valida√ß√£o cruzada
- `--no-leakage-prevention`: Desativa a detec√ß√£o de data leakage
- `--no-feature-selection`: Desativa a sele√ß√£o de features
- `--cv-folds 10`: Altera o n√∫mero de folds na valida√ß√£o cruzada (padr√£o: 5)

### Treinamento do Modelo

Para treinar modelos separadamente:

```bash
# Treinar o modelo RandomForest padr√£o
python src/models/train_simple.py

# Comparar diferentes modelos
python src/models/train_simple.py --compare
```

### MLflow - Tracking de Experimentos

Para gerenciar experimentos MLflow:

```bash
# Iniciar servidor MLflow
python src/models/mlflow_server.py

# Listar experimentos
python src/models/mlflow_server.py --list

# Excluir experimento
python src/models/mlflow_server.py --delete "Decision-Scoring-Model"
```

Para mais detalhes sobre MLflow, consulte o guia em [docs/mlflow_guide.md](docs/mlflow_guide.md)

## üöÄ API de Scoring

O projeto inclui uma API para servir o modelo de Machine Learning treinado:

### Executando a API Localmente
```bash
./scripts/start_api.sh
```

### Utilizando Docker
```bash
docker build -t decision-scoring-api .
docker run -p 8000:8000 decision-scoring-api
```

### Endpoints Principais
- `POST /score` - Endpoint principal para predi√ß√µes individuais
- `POST /score/batch` - Processamento de m√∫ltiplos candidatos em lote
- `GET /health` - Health check da API
- `GET /metrics` - M√©tricas de desempenho da API (requer autentica√ß√£o admin)
- `GET /monitoring/drift` - An√°lise de drift do modelo (requer autentica√ß√£o admin)
- `GET /monitoring/drift/visualization` - Visualiza√ß√£o de drift para uma feature espec√≠fica
- `GET /monitoring/metrics/history` - Hist√≥rico de m√©tricas do modelo
- `GET /monitoring/predictions/recent` - Estat√≠sticas sobre predi√ß√µes recentes

### Sistema de Monitoramento

O projeto inclui um sistema completo de monitoramento para acompanhar o desempenho do modelo e detectar drift:

#### Dashboard de M√©tricas

Para iniciar o dashboard de monitoramento:

```bash
./scripts/start_dashboard.sh
```

O dashboard fornece:
- Visualiza√ß√£o em tempo real das m√©tricas do modelo
- An√°lise de drift entre dados de treino e produ√ß√£o
- Hist√≥rico de desempenho do modelo
- Estat√≠sticas sobre predi√ß√µes recentes

#### Verifica√ß√£o de Drift

Para verificar drift e gerar alertas:

```bash
./scripts/check_drift.sh
```

Consulte a [documenta√ß√£o completa do sistema de monitoramento](docs/monitoring_guide.md) para mais detalhes.
- `/docs` - Documenta√ß√£o interativa (Swagger UI)

### Autentica√ß√£o
Todas as requisi√ß√µes devem incluir um cabe√ßalho `X-API-Key` com uma chave v√°lida:
- `fiap-api-key`: Acesso de administrador (todos os endpoints) - Use esta chave para os exemplos
- `local-api-key`: Acesso de administrador (todos os endpoints) - Configurada no docker-compose
- `test-api-key`: Acesso somente leitura (endpoints b√°sicos)

> **Nota**: A chave `fiap-api-key` est√° sempre dispon√≠vel e √© recomendada para os exemplos.

### Exemplo de Requisi√ß√£o
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "X-API-Key: fiap-api-key" \
  -H "Content-Type: application/json" \
  -H "accept: application/json" \
  -d '{
    "idade": 28,
    "experiencia": 5,
    "educacao": "ensino_superior",
    "area_formacao": "tecnologia",
    "vaga_titulo": "Desenvolvedor Python",
    "vaga_area": "tecnologia",
    "vaga_senioridade": "pleno"
  }'
```

### Exemplo de Resposta
```json
{
  "prediction": 1,
  "probability": 0.85,
  "recommendation": "Recomendado",
  "comment": "A avalia√ß√£o t√©cnica sugere boa adequa√ß√£o para a fun√ß√£o de Desenvolvedor Python na √°rea de tecnologia, n√≠vel pleno. Destaca-se forma√ß√£o superior na √°rea de tecnologia e 5.0 anos de experi√™ncia relevante.",
  "vaga_info": {
    "id": "vaga-123",
    "titulo": "Desenvolvedor Python",
    "area": "tecnologia",
    "senioridade": "pleno"
  },
  "match_score": 0.78
}
```

### Implanta√ß√£o no Render
O projeto pode ser facilmente implantado na plataforma Render usando Docker ou o arquivo de configura√ß√£o inclu√≠do.

#### Op√ß√µes de Implanta√ß√£o
1. **Via Blueprint (config/render/render.yaml)**: Implanta√ß√£o autom√°tica usando nosso arquivo de configura√ß√£o
2. **Via Docker**: Implanta√ß√£o manual do cont√™iner Docker usando o config/docker/api/Dockerfile inclu√≠do
3. **Sem Docker**: Implanta√ß√£o usando o ambiente Python do Render e o config/render/Procfile

## üìù Dados

O projeto utiliza tr√™s datasets em formato JSON na pasta `data/`:
- **applicants.json**: Dados dos candidatos ao processo seletivo
- **prospects.json**: Dados das entrevistas e prospects
- **vagas.json**: Informa√ß√µes sobre as vagas dispon√≠veis

### Estrutura dos Dados
- **Candidatos**: Dataset principal com informa√ß√µes dos candidatos
- **Entrevistas**: Dados das entrevistas realizadas  
- **Vagas**: Informa√ß√µes sobre as vagas dispon√≠veis

## üîç An√°lise Explorat√≥ria

O notebook principal inclui:
- Importa√ß√£o e carregamento dos dados JSON
- An√°lise da estrutura e qualidade dos dados
- Estat√≠sticas descritivas
- Visualiza√ß√µes gr√°ficas interativas
- Identifica√ß√£o de padr√µes e outliers
- An√°lise de correla√ß√µes
- Detec√ß√£o de valores ausentes

### Principais Insights
- An√°lise de padr√µes nos dados de candidatos
- Identifica√ß√£o de correla√ß√µes entre vari√°veis
- Detec√ß√£o e tratamento de outliers
- Distribui√ß√µes das vari√°veis principais

## üß† Recursos de IA e LLM

O projeto agora inclui recursos de IA para gerar coment√°rios personalizados sobre candidatos:

### Coment√°rios LLM para Recomenda√ß√µes
A API agora gera automaticamente coment√°rios em linguagem natural para cada recomenda√ß√£o de candidato. Este recurso:

- Analisa o perfil do candidato e os requisitos da vaga
- Gera texto explicativo sobre o motivo da recomenda√ß√£o positiva ou negativa
- Adapta o tom e conte√∫do com base na probabilidade da predi√ß√£o
- Inclui detalhes relevantes como experi√™ncia e forma√ß√£o do candidato

### Como Funciona
O sistema utiliza:
1. **TextBlob** para processamento de linguagem natural
2. **Templates personalizados** para diferentes cen√°rios de recomenda√ß√£o
3. **L√≥gica contextual** para selecionar os detalhes mais relevantes a destacar

Para mais detalhes sobre esta funcionalidade, consulte a documenta√ß√£o em [docs/llm_comments.md](docs/llm_comments.md)

## üîÆ Pr√≥ximos Passos

1. **Experimenta√ß√£o com MLflow**: 
   - ‚úÖ Otimiza√ß√£o de hiperpar√¢metros - implementado com RandomizedSearchCV
   - ‚úÖ Teste de diferentes algoritmos - implementado com compara√ß√£o de modelos
   - ‚úÖ Compara√ß√£o de m√©tricas de desempenho - tracking com MLflow

2. **Implementa√ß√£o de Clustering**:
   - Segmenta√ß√£o de candidatos por perfil
   - Identifica√ß√£o de grupos de vagas similares
   - Integra√ß√£o do clustering ao scoring model

3. **Melhorias no Modelo**:
   - Feature engineering avan√ßado
   - Implementa√ß√£o de t√©cnicas de deep learning
   - Valida√ß√£o cruzada para maior robustez

4. **Produtiviza√ß√£o**:
   - ‚úÖ API REST para servir o modelo - implementada com FastAPI
   - ‚úÖ Implanta√ß√£o no Render - configurada com Docker
   - ‚úÖ Coment√°rios LLM para explicabilidade - implementado com TextBlob
   - Monitoramento cont√≠nuo de performance
   - Pipeline de retreinamento autom√°tico

## ü§ù Contribui√ß√£o

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa Apache 2.0. Veja o arquivo [`LICENSE`](LICENSE) para mais detalhes.

## üß™ Testes Unit√°rios

O projeto conta com testes unit√°rios para garantir a qualidade e o funcionamento correto dos componentes da pipeline. Para executar os testes:

```bash
# Execute o script de testes
./scripts/run_tests.sh
```

Para mais detalhes sobre os testes implementados, consulte o [README dos testes](tests/README.md).

## üìû Contato

FIAP Tech Challenge 05 - [@rivolela](https://github.com/rivolela/fiap_tech_challenge_05)

---
**Nota**: Certifique-se de que os arquivos JSON estejam dispon√≠veis na pasta `data/` antes de executar o notebook de an√°lise.



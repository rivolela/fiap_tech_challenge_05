{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3fe113a",
   "metadata": {},
   "source": [
    "# An√°lise de Ajuste de Threshold para Dados Desbalanceados\n",
    "\n",
    "Este notebook demonstra como ajustar o threshold de classifica√ß√£o para melhorar o desempenho de modelos com dados desbalanceados, especialmente em termos de recall.\n",
    "\n",
    "Os modelos de classifica√ß√£o padr√£o geralmente usam um threshold de 0.5 para decidir se um exemplo pertence √† classe positiva ou negativa. No entanto, quando os dados est√£o desbalanceados (ou seja, uma classe √© muito mais frequente que a outra), esse threshold padr√£o pode n√£o ser ideal.\n",
    "\n",
    "Neste notebook, vamos:\n",
    "1. Carregar dados de candidatos com classes desbalanceadas\n",
    "2. Treinar um modelo de classifica√ß√£o \n",
    "3. Avaliar o desempenho com threshold padr√£o (0.5)\n",
    "4. Encontrar um threshold √≥timo usando curvas ROC e Precision-Recall\n",
    "5. Avaliar o desempenho com threshold ajustado\n",
    "6. Visualizar o impacto de diferentes thresholds nas m√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necess√°rias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                            precision_recall_curve, roc_curve, auc,\n",
    "                            f1_score, precision_score, recall_score, \n",
    "                            accuracy_score, average_precision_score, roc_auc_score)\n",
    "\n",
    "# Configura√ß√µes para visualiza√ß√£o\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59424c82",
   "metadata": {},
   "source": [
    "## Carregamento e Prepara√ß√£o dos Dados\n",
    "\n",
    "Primeiro, vamos carregar os dados processados e verificar a distribui√ß√£o das classes.\n",
    "O nosso modelo est√° tentando prever a vari√°vel `target_sucesso` que indica se um candidato foi contratado com sucesso (1) ou n√£o (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados processados\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/complete_processed_data.csv')\n",
    "    print(f\"‚úÖ Dados carregados: {df.shape[0]} registros, {df.shape[1]} colunas\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Arquivo de dados n√£o encontrado. Verifique o caminho.\")\n",
    "    \n",
    "# Verificar a presen√ßa da vari√°vel target\n",
    "target = 'target_sucesso'\n",
    "if target in df.columns:\n",
    "    # Distribui√ß√£o da vari√°vel target\n",
    "    target_dist = df[target].value_counts(normalize=True) * 100\n",
    "    print(\"\\nüìä Distribui√ß√£o do Target:\")\n",
    "    for value, pct in target_dist.items():\n",
    "        print(f\"  - Classe {value}: {pct:.1f}%\")\n",
    "    \n",
    "    # Visualizar distribui√ß√£o\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(x=target, data=df)\n",
    "    plt.title('Distribui√ß√£o da Vari√°vel Target (Sucesso na Contrata√ß√£o)')\n",
    "    plt.xlabel('Sucesso na Contrata√ß√£o (0=N√£o, 1=Sim)')\n",
    "    plt.ylabel('N√∫mero de Candidatos')\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', \n",
    "                    (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"‚ùå Vari√°vel target '{target}' n√£o encontrada nos dados.\")\n",
    "    \n",
    "# Separar features e target\n",
    "if target in df.columns:\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    print(f\"\\n‚úÖ Features e target separados: {X.shape[1]} features, {len(y)} exemplos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40488c3",
   "metadata": {},
   "source": [
    "## Carregamento do Modelo Treinado\n",
    "\n",
    "Vamos carregar o modelo pr√©-treinado para avaliar seu desempenho com diferentes thresholds.\n",
    "Primeiro, precisamos verificar se o modelo j√° existe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo treinado\n",
    "model_path = '../models/scoring_model.pkl'\n",
    "\n",
    "try:\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    print(f\"‚úÖ Modelo carregado com sucesso: {type(model).__name__}\")\n",
    "    \n",
    "    # Extrair informa√ß√µes sobre o modelo\n",
    "    if hasattr(model, 'steps'):\n",
    "        for name, step in model.named_steps.items():\n",
    "            print(f\"  - {name}: {type(step).__name__}\")\n",
    "    elif hasattr(model, 'estimators_'):\n",
    "        print(f\"  - N√∫mero de estimadores: {len(model.estimators_)}\")\n",
    "    else:\n",
    "        print(\"  - Informa√ß√µes detalhadas n√£o dispon√≠veis para este tipo de modelo\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Modelo n√£o encontrado em {model_path}\")\n",
    "    print(\"üîÑ Treinando um modelo simples para demonstra√ß√£o...\")\n",
    "    \n",
    "    # Se n√£o encontrarmos o modelo, treinaremos um modelo simples para demonstra√ß√£o\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Dividir os dados em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Treinar um modelo RandomForest\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"‚úÖ Modelo de demonstra√ß√£o treinado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a772abd",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o com Threshold Padr√£o (0.5)\n",
    "\n",
    "Vamos avaliar o desempenho do modelo usando o threshold padr√£o de 0.5 para classifica√ß√£o e calcular diversas m√©tricas para entender como o modelo se comporta com dados desbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f36868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados em treino e teste se n√£o foi feito anteriormente\n",
    "try:\n",
    "    X_test\n",
    "except NameError:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"‚úÖ Dados divididos em treino e teste: {len(X_train)} exemplos de treino, {len(X_test)} exemplos de teste\")\n",
    "\n",
    "# Obter probabilidades de predi√ß√£o\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]  # Probabilidade da classe positiva\n",
    "    print(\"‚úÖ Probabilidades de predi√ß√£o obtidas\")\n",
    "else:\n",
    "    # Se o modelo n√£o tiver predict_proba, usar decis√£o como probabilidade\n",
    "    y_proba = model.predict(X_test)\n",
    "    print(\"‚ö†Ô∏è Modelo n√£o possui m√©todo predict_proba, usando decis√µes como probabilidades\")\n",
    "\n",
    "# Predi√ß√µes com threshold padr√£o de 0.5\n",
    "threshold_default = 0.5\n",
    "y_pred_default = (y_proba >= threshold_default).astype(int)\n",
    "\n",
    "# Calcular m√©tricas de classifica√ß√£o com threshold padr√£o\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "precision_default = precision_score(y_test, y_pred_default)\n",
    "recall_default = recall_score(y_test, y_pred_default)\n",
    "f1_default = f1_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"\\nüìä Performance com Threshold Padr√£o (0.5):\")\n",
    "print(f\"  - Acur√°cia: {accuracy_default:.4f}\")\n",
    "print(f\"  - Precis√£o: {precision_default:.4f}\")\n",
    "print(f\"  - Recall: {recall_default:.4f}\")\n",
    "print(f\"  - F1-Score: {f1_default:.4f}\")\n",
    "print(f\"  - AUC-ROC: {auc_default:.4f}\")\n",
    "\n",
    "# Exibir relat√≥rio de classifica√ß√£o detalhado\n",
    "print(\"\\nüìã Relat√≥rio de Classifica√ß√£o Detalhado:\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "\n",
    "# Visualizar matriz de confus√£o\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_default)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['N√£o Contratado', 'Contratado'],\n",
    "            yticklabels=['N√£o Contratado', 'Contratado'])\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.title(f'Matriz de Confus√£o (Threshold = {threshold_default})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220cbf2d",
   "metadata": {},
   "source": [
    "## Encontrando o Threshold √ìtimo\n",
    "\n",
    "Para dados desbalanceados, o threshold padr√£o de 0.5 geralmente n√£o √© ideal. Vamos usar diferentes m√©todos para encontrar um threshold mais adequado:\n",
    "\n",
    "1. **Curva Precision-Recall**: Para datasets desbalanceados, esta curva √© geralmente mais informativa que a curva ROC.\n",
    "2. **Curva ROC**: Permite visualizar trade-off entre taxa de verdadeiros positivos e falsos positivos.\n",
    "3. **F1-Score para diferentes thresholds**: Encontrar o threshold que maximiza o F1-Score.\n",
    "\n",
    "Vamos implementar essas abordagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9684f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Curva Precision-Recall\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Calcular F1 score para cada threshold\n",
    "f1_scores = []\n",
    "for p, r in zip(precision, recall):\n",
    "    if p + r == 0:  # Evitar divis√£o por zero\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2 * (p * r) / (p + r)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Encontrar o threshold que maximiza o F1-score\n",
    "optimal_idx_f1 = np.argmax(f1_scores)\n",
    "optimal_threshold_f1 = thresholds_pr[optimal_idx_f1] if optimal_idx_f1 < len(thresholds_pr) else 0.5\n",
    "\n",
    "# 2. Curva ROC\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Encontrar o threshold que maximiza a dist√¢ncia √† linha aleat√≥ria (ponto mais distante da linha diagonal)\n",
    "# Tamb√©m conhecido como ponto J de Youden\n",
    "distances = tpr - fpr\n",
    "optimal_idx_roc = np.argmax(distances)\n",
    "optimal_threshold_roc = thresholds_roc[optimal_idx_roc]\n",
    "\n",
    "# 3. Calcular m√©tricas para v√°rios thresholds\n",
    "thresholds_range = np.linspace(0.05, 0.95, 19)  # De 0.05 a 0.95 em 19 steps\n",
    "metrics = []\n",
    "\n",
    "for threshold in thresholds_range:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    metrics.append({\n",
    "        'threshold': threshold,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Encontrar o threshold que maximiza o F1-score na nossa grade\n",
    "optimal_threshold_grid = metrics_df.loc[metrics_df['f1'].idxmax(), 'threshold']\n",
    "\n",
    "print(f\"Threshold √≥timo (maximizando F1 na curva PR): {optimal_threshold_f1:.4f}\")\n",
    "print(f\"Threshold √≥timo (maximizando J de Youden na curva ROC): {optimal_threshold_roc:.4f}\")\n",
    "print(f\"Threshold √≥timo (maximizando F1 em nossa grade): {optimal_threshold_grid:.4f}\")\n",
    "\n",
    "# Escolher o threshold final (m√©dia dos m√©todos)\n",
    "final_threshold = np.mean([optimal_threshold_f1, optimal_threshold_roc, optimal_threshold_grid])\n",
    "print(f\"\\nüéØ Threshold recomendado final: {final_threshold:.4f}\")\n",
    "\n",
    "# Visualizar as curvas\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Curva Precision-Recall\n",
    "ax1.plot(recall, precision, label='Curva Precision-Recall')\n",
    "ax1.scatter(recall[optimal_idx_f1], precision[optimal_idx_f1], \n",
    "           color='red', label=f'Threshold √ìtimo: {optimal_threshold_f1:.4f}')\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title('Curva Precision-Recall')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Curva ROC\n",
    "ax2.plot(fpr, tpr, label=f'Curva ROC (AUC = {auc_default:.4f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--', label='Aleat√≥rio')\n",
    "ax2.scatter(fpr[optimal_idx_roc], tpr[optimal_idx_roc], \n",
    "           color='red', label=f'Threshold √ìtimo: {optimal_threshold_roc:.4f}')\n",
    "ax2.set_xlabel('Taxa de Falsos Positivos')\n",
    "ax2.set_ylabel('Taxa de Verdadeiros Positivos')\n",
    "ax2.set_title('Curva ROC')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218211e8",
   "metadata": {},
   "source": [
    "## Visualiza√ß√£o do Impacto de Diferentes Thresholds\n",
    "\n",
    "Agora vamos visualizar como as m√©tricas de desempenho (precis√£o, recall, F1 e acur√°cia) variam conforme mudamos o threshold de classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92598fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar as m√©tricas para diferentes thresholds\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotar cada m√©trica\n",
    "plt.plot(metrics_df['threshold'], metrics_df['accuracy'], 'b-', label='Acur√°cia')\n",
    "plt.plot(metrics_df['threshold'], metrics_df['precision'], 'g-', label='Precis√£o')\n",
    "plt.plot(metrics_df['threshold'], metrics_df['recall'], 'r-', label='Recall')\n",
    "plt.plot(metrics_df['threshold'], metrics_df['f1'], 'purple', label='F1-Score')\n",
    "\n",
    "# Adicionar linhas para os thresholds √≥timos\n",
    "plt.axvline(x=optimal_threshold_f1, color='red', linestyle='--', alpha=0.5, label=f'Threshold PR: {optimal_threshold_f1:.4f}')\n",
    "plt.axvline(x=optimal_threshold_roc, color='green', linestyle='--', alpha=0.5, label=f'Threshold ROC: {optimal_threshold_roc:.4f}')\n",
    "plt.axvline(x=final_threshold, color='black', linestyle='-', alpha=0.7, label=f'Threshold Final: {final_threshold:.4f}')\n",
    "plt.axvline(x=0.5, color='gray', linestyle=':', alpha=0.7, label='Threshold Padr√£o: 0.5')\n",
    "\n",
    "# Configurar o gr√°fico\n",
    "plt.title('Impacto do Threshold nas M√©tricas de Classifica√ß√£o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Valor da M√©trica')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.xticks(np.arange(0, 1.05, 0.05))\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Visualiza√ß√£o em formato de tabela para thresholds selecionados\n",
    "selected_thresholds = [0.1, 0.2, 0.25, 0.3, 0.4, 0.5]\n",
    "selected_metrics = []\n",
    "\n",
    "for threshold in selected_thresholds:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Contar positivos preditos\n",
    "    positivos_preditos = np.sum(y_pred == 1)\n",
    "    pct_positivos = (positivos_preditos / len(y_pred)) * 100\n",
    "    \n",
    "    selected_metrics.append({\n",
    "        'threshold': threshold,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'positivos_preditos': positivos_preditos,\n",
    "        'pct_positivos': pct_positivos\n",
    "    })\n",
    "\n",
    "# Converter para DataFrame e exibir\n",
    "selected_df = pd.DataFrame(selected_metrics)\n",
    "selected_df = selected_df.round(4)\n",
    "selected_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5882ef",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o com Threshold Ajustado\n",
    "\n",
    "Agora vamos avaliar o desempenho do modelo usando o threshold otimizado que encontramos. Vamos comparar as m√©tricas e a matriz de confus√£o com o threshold padr√£o de 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0177685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar o threshold otimizado\n",
    "threshold_optimized = final_threshold\n",
    "y_pred_optimized = (y_proba >= threshold_optimized).astype(int)\n",
    "\n",
    "# Calcular m√©tricas de classifica√ß√£o com threshold otimizado\n",
    "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "precision_optimized = precision_score(y_test, y_pred_optimized)\n",
    "recall_optimized = recall_score(y_test, y_pred_optimized)\n",
    "f1_optimized = f1_score(y_test, y_pred_optimized)\n",
    "auc_optimized = auc_default  # AUC √© invariante ao threshold\n",
    "\n",
    "# Comparar resultados\n",
    "results = {\n",
    "    'M√©trica': ['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score', 'AUC-ROC'],\n",
    "    'Threshold Padr√£o (0.5)': [accuracy_default, precision_default, recall_default, f1_default, auc_default],\n",
    "    f'Threshold Otimizado ({threshold_optimized:.3f})': [accuracy_optimized, precision_optimized, recall_optimized, f1_optimized, auc_optimized],\n",
    "    'Diferen√ßa': [\n",
    "        accuracy_optimized - accuracy_default,\n",
    "        precision_optimized - precision_default,\n",
    "        recall_optimized - recall_default,\n",
    "        f1_optimized - f1_default,\n",
    "        0  # AUC √© invariante ao threshold\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Criar DataFrame para visualiza√ß√£o\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.round(4)\n",
    "results_df\n",
    "\n",
    "# Calcular varia√ß√£o percentual nas m√©tricas\n",
    "percent_change = {\n",
    "    'M√©trica': ['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score'],\n",
    "    'Varia√ß√£o %': [\n",
    "        (accuracy_optimized - accuracy_default) / accuracy_default * 100,\n",
    "        (precision_optimized - precision_default) / precision_default * 100,\n",
    "        (recall_optimized - recall_default) / recall_default * 100 if recall_default > 0 else float('inf'),\n",
    "        (f1_optimized - f1_default) / f1_default * 100 if f1_default > 0 else float('inf')\n",
    "    ]\n",
    "}\n",
    "percent_df = pd.DataFrame(percent_change)\n",
    "percent_df['Varia√ß√£o %'] = percent_df['Varia√ß√£o %'].round(2)\n",
    "\n",
    "# Visualizar matrizes de confus√£o lado a lado\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Matriz de confus√£o com threshold padr√£o\n",
    "cm_default = confusion_matrix(y_test, y_pred_default)\n",
    "sns.heatmap(cm_default, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "            xticklabels=['N√£o Contratado', 'Contratado'],\n",
    "            yticklabels=['N√£o Contratado', 'Contratado'])\n",
    "ax1.set_xlabel('Predito')\n",
    "ax1.set_ylabel('Real')\n",
    "ax1.set_title(f'Matriz de Confus√£o (Threshold = 0.5)')\n",
    "\n",
    "# Matriz de confus√£o com threshold otimizado\n",
    "cm_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
    "sns.heatmap(cm_optimized, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "            xticklabels=['N√£o Contratado', 'Contratado'],\n",
    "            yticklabels=['N√£o Contratado', 'Contratado'])\n",
    "ax2.set_xlabel('Predito')\n",
    "ax2.set_ylabel('Real')\n",
    "ax2.set_title(f'Matriz de Confus√£o (Threshold = {threshold_optimized:.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Exibir tamb√©m a varia√ß√£o percentual\n",
    "percent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8474c",
   "metadata": {},
   "source": [
    "## Conclus√µes e Recomenda√ß√µes\n",
    "\n",
    "Com base nas an√°lises realizadas, podemos tirar algumas conclus√µes importantes sobre o ajuste de threshold para o nosso modelo de scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar fun√ß√£o para salvar o threshold otimizado\n",
    "def save_optimal_threshold(threshold, output_file='../config/optimal_threshold.txt'):\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(f\"{threshold}\")\n",
    "    print(f\"‚úÖ Threshold otimizado salvo em {output_file}\")\n",
    "\n",
    "# Salvar o threshold otimizado em um arquivo de configura√ß√£o\n",
    "try:\n",
    "    save_optimal_threshold(threshold_optimized)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao salvar o threshold: {str(e)}\")\n",
    "\n",
    "# Resumo das conclus√µes em formato de texto\n",
    "print(\"üìù CONCLUS√ïES DA AN√ÅLISE DE THRESHOLD:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"1. O threshold padr√£o (0.5) resultou em:\")\n",
    "print(f\"   - Alta precis√£o: {precision_default:.4f}\")\n",
    "print(f\"   - Baixo recall: {recall_default:.4f}\")\n",
    "print(f\"   - F1-score: {f1_default:.4f}\")\n",
    "print(f\"   Este comportamento √© t√≠pico em problemas com dados desbalanceados.\")\n",
    "print()\n",
    "print(f\"2. O threshold otimizado ({threshold_optimized:.4f}) resultou em:\")\n",
    "print(f\"   - Precis√£o: {precision_optimized:.4f} ({(precision_optimized - precision_default) / precision_default * 100:.1f}%)\")\n",
    "print(f\"   - Recall: {recall_optimized:.4f} ({(recall_optimized - recall_default) / recall_default * 100:.1f}%)\" if recall_default > 0 else f\"   - Recall: {recall_optimized:.4f} (‚àû%)\")\n",
    "print(f\"   - F1-score: {f1_optimized:.4f} ({(f1_optimized - f1_default) / f1_default * 100:.1f}%)\" if f1_default > 0 else f\"   - F1-score: {f1_optimized:.4f} (‚àû%)\")\n",
    "print()\n",
    "print(\"3. Recomenda√ß√µes:\")\n",
    "print(f\"   - Usar threshold de {threshold_optimized:.4f} para melhorar o equil√≠brio entre precis√£o e recall\")\n",
    "print(\"   - Configurar via vari√°vel de ambiente CLASSIFICATION_THRESHOLD\")\n",
    "print(\"   - Monitorar o impacto no ambiente de produ√ß√£o\")\n",
    "print(\"   - Reavaliar periodicamente conforme novos dados s√£o coletados\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a1a9f",
   "metadata": {},
   "source": [
    "## Como Implementar o Threshold Ajustado na API\n",
    "\n",
    "O threshold otimizado pode ser implementado na API de scoring atrav√©s das seguintes etapas:\n",
    "\n",
    "1. **Configurar via vari√°vel de ambiente**: Definir `CLASSIFICATION_THRESHOLD=0.25` (ou o valor otimizado encontrado)\n",
    "\n",
    "2. **Modificar o c√≥digo de predi√ß√£o**: Atualizar a fun√ß√£o de predi√ß√£o para usar o threshold configur√°vel:\n",
    "\n",
    "```python\n",
    "def get_classification_threshold():\n",
    "    \"\"\"Obt√©m o threshold configurado ou usa o valor padr√£o otimizado\"\"\"\n",
    "    try:\n",
    "        threshold = float(os.environ.get(\"CLASSIFICATION_THRESHOLD\", \"0.25\"))\n",
    "        threshold = max(0.01, min(threshold, 0.99))  # Limitar entre 0.01 e 0.99\n",
    "        return threshold\n",
    "    except (ValueError, TypeError):\n",
    "        return 0.25  # Valor otimizado padr√£o\n",
    "        \n",
    "def predict(data):\n",
    "    # Obter probabilidade\n",
    "    probability = model.predict_proba(data)[:, 1]\n",
    "    \n",
    "    # Usar threshold ajustado\n",
    "    threshold = get_classification_threshold()\n",
    "    prediction = (probability >= threshold).astype(int)\n",
    "    \n",
    "    return {\"prediction\": prediction, \"probability\": probability, \"threshold\": threshold}\n",
    "```\n",
    "\n",
    "3. **Documentar a mudan√ßa**: Explicar o motivo e o impacto da altera√ß√£o para futuras refer√™ncias\n",
    "\n",
    "4. **Monitorar o desempenho**: Verificar o impacto do novo threshold no ambiente de produ√ß√£o"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
